{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFE7UQN1b_5G"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "import fnmatch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# char_list:   'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "# total number of our output classes: len(char_list)\n",
        "characters = string.ascii_letters + string.digits\n",
        "\n",
        "def encode_to_labels(text):\n",
        "    # encoding each output word into digits\n",
        "    return [characters.index(char) for char in text if char in characters]"
      ],
      "metadata": {
        "id": "gc0daaNSdo2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = r'C:\\Users\\twalunjk\\Downloads\\mjsynth\\mnt\\ramdisk\\max\\90kDICT32px'"
      ],
      "metadata": {
        "id": "L6D0NgEYeJoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lists for training dataset\n",
        "images = np.zeros((390000, 32, 128, 1), dtype='uint8')\n",
        "texts = []\n",
        "input_lengths = np.full((390000,), 31, dtype='uint8')\n",
        "label_lengths = np.zeros((390000,), dtype='uint8')\n",
        "\n",
        "max_text_len = 0\n",
        "\n",
        "for i, (root, _, filenames) in enumerate(os.walk(data_path)):\n",
        "    for filename in fnmatch.filter(filenames, '*.jpg'):\n",
        "        try:\n",
        "            image = cv2.cvtColor(cv2.imread(os.path.join(root, filename)), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # convert each image of shape (32, 128, 1)\n",
        "            width, height = image.shape\n",
        "            if height > 128 or width > 32:\n",
        "                continue\n",
        "\n",
        "            if width < 32:\n",
        "                image = np.vstack((image, np.full((32-width, height), 255)))\n",
        "\n",
        "            if height < 128:\n",
        "                image = np.hstack((image, np.full((32, 128-height), 255)))\n",
        "\n",
        "            image = np.expand_dims(image, axis=2)\n",
        "\n",
        "            # get the text from the image\n",
        "            text = filename.split('_')[1]\n",
        "\n",
        "            # compute maximum length of the text\n",
        "            max_text_len = max(max_text_len, len(text))\n",
        "\n",
        "            if len(text) == 0:\n",
        "                print(text)\n",
        "                continue\n",
        "\n",
        "            label_lengths[i] = len(text)\n",
        "            images[i] = image\n",
        "            texts.append(encode_to_labels(text))\n",
        "\n",
        "            sys.stdout.write('\\r' + str(i) + ' ' + str(np.count_nonzero(label_lengths)))\n",
        "\n",
        "            # break the loop if total data is 150000\n",
        "            if i == 389999:\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print('\\n', os.path.join(root, filename), str(e))\n",
        "\n",
        "    if i == 389999:\n",
        "        break"
      ],
      "metadata": {
        "id": "C80XSPE6eSEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad each output label to maximum text length\n",
        "padded_texts = pad_sequences(texts, maxlen=max_text_len, padding='post', value=len(characters))"
      ],
      "metadata": {
        "id": "uxl02vwUecg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_lengths.shape)\n",
        "print(input_lengths.shape)\n",
        "print(images.shape)\n",
        "print(padded_texts.shape)"
      ],
      "metadata": {
        "id": "mZhkL2EYefGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = r'C:\\Users\\twalunjk\\Downloads\\DL\\save'\n",
        "np.save(os.path.join(save_path, 'label_lengths.npy'), label_lengths)\n",
        "np.save(os.path.join(save_path, 'input_lengths.npy'), input_lengths)\n",
        "np.save(os.path.join(save_path, 'images.npy'), images)\n",
        "np.save(os.path.join(save_path, 'padded_texts.npy'), padded_texts)\n",
        "np.save(os.path.join(save_path, 'max_text_len.npy'), max_text_len)"
      ],
      "metadata": {
        "id": "afg9s0Hsej8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following after CRNN"
      ],
      "metadata": {
        "id": "j6usRqqGettz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, Dropout\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import keras\n",
        "import numpy as np\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "xBKanpAYe162"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(32,128,1))\n",
        "normalized_inputs = Lambda(lambda x: x / 255) (input_layer)\n",
        "\n",
        "conv_layer1 = Conv2D(16, (3,3), activation = 'relu', kernel_initializer='he_normal' ,padding='same')(normalized_inputs)\n",
        "conv_layer1 = Dropout(0.25)(conv_layer1)\n",
        "conv_layer1 = Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_normal' ,padding='same')(conv_layer1)\n",
        "pool_layer1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_layer1)\n",
        "\n",
        "conv_layer2 = Conv2D(32, (3,3), activation = 'relu',kernel_initializer='he_normal' , padding='same')(pool_layer1)\n",
        "conv_layer2 = BatchNormalization(axis=-1)(conv_layer2)\n",
        "conv_layer2 = Dropout(0.25)(conv_layer2)\n",
        "conv_layer2 = Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_normal' ,padding='same')(conv_layer2)\n",
        "pool_layer2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_layer2)\n",
        "\n",
        "conv_layer3 = Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_normal' ,padding='same')(pool_layer2)\n",
        "conv_layer3 = BatchNormalization(axis=-1)(conv_layer3)\n",
        "conv_layer3 = Dropout(0.25)(conv_layer3)\n",
        "conv_layer3 = Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_normal' ,padding='same')(conv_layer3)\n",
        "conv_layer4 = Conv2D(64, (3,3), activation = 'relu', kernel_initializer='he_normal' ,padding='same')(conv_layer3)\n",
        "pool_layer4 = MaxPool2D(pool_size=(2, 1))(conv_layer4)\n",
        "\n",
        "conv_layer5 = Conv2D(256, (3,3), activation = 'relu',kernel_initializer='he_normal' , padding='same')(pool_layer4)\n",
        "batch_norm_layer5 = BatchNormalization()(conv_layer5)\n",
        "\n",
        "conv_layer6 = Conv2D(256, (3,3), activation = 'relu',kernel_initializer='he_normal' , padding='same')(batch_norm_layer5)\n",
        "batch_norm_layer6 = BatchNormalization()(conv_layer6)\n",
        "pool_layer6 = MaxPool2D(pool_size=(2, 1))(batch_norm_layer6)\n",
        "\n",
        "conv_layer7 = Conv2D(512, (2,2), activation = 'relu')(pool_layer6)\n",
        "\n",
        "squeezed_layer = Lambda(lambda x: K.squeeze(x, 1))(conv_layer7)\n",
        "\n",
        "blstm_layer1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed_layer)\n",
        "blstm_layer2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_layer1)\n",
        "\n",
        "output_layer = Dense(62+1, activation = 'softmax')(blstm_layer2)\n",
        "\n",
        "# model to be used at test time\n",
        "model = Model(input_layer, output_layer)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lOJqFCpjgIwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_and_prediction(x,y):\n",
        "\n",
        "  # load the saved best model weights\n",
        "  model.load_weights(r'C:\\Users\\twalunjk\\Downloads\\DL\\save\\best_model.hdf5')\n",
        "  prediction = model.predict(x.reshape(1,32,128,1))\n",
        "\n",
        "  # use CTC decoder\n",
        "  out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        "  x = x.reshape(32,128)\n",
        "  plt.title('Input Image')\n",
        "  plt.imshow(x)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  # see the results\n",
        "  for x in out:\n",
        "      print(\"predicted text = \", end = '')\n",
        "      for p in x:\n",
        "          if int(p) != -1:\n",
        "              print(char_list[int(p)], end = '')\n",
        "      print('\\n')"
      ],
      "metadata": {
        "id": "DEmzOX98grYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(8):\n",
        "  i = np.random.randint(300000)\n",
        "  display_image_and_prediction(training_img[i],train_padded_txt[i])"
      ],
      "metadata": {
        "id": "zC547I5hg5VO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}